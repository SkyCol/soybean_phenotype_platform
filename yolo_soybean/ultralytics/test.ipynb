{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.path)\n",
    "\n",
    "sys.path.append('/hy-tmp/yolo_soybean/ultralytics')\n",
    "\n",
    "model = YOLO('best.pt')\n",
    "# model = YOLO('ultralytics/cfg/models/v8/yolov8n.yaml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO(\"yolov8m.yaml\")  # build a new model from YAML\n",
    "model = YOLO(r\"D:\\PC\\cyvision\\soybean_phenomic\\yolo_soybean\\ckpts\\yolov8m.pt\")  # load a pretrained model (recommended for training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer                                     name  gradient   parameters                shape         mu      sigma\n",
      "    0                      model.0.conv.weight     False         1296        [48, 3, 3, 3]   -0.00132      0.112 torch.float32\n",
      "    1                        model.0.bn.weight     False           48                 [48]       3.25      0.805 torch.float32\n",
      "    2                          model.0.bn.bias     False           48                 [48]    -0.0758       2.28 torch.float32\n",
      "    3                      model.1.conv.weight     False        41472       [96, 48, 3, 3]  -0.000509     0.0235 torch.float32\n",
      "    4                        model.1.bn.weight     False           96                 [96]       2.95      0.632 torch.float32\n",
      "    5                          model.1.bn.bias     False           96                 [96]      0.439       1.35 torch.float32\n",
      "    6                  model.2.cv1.conv.weight     False         9216       [96, 96, 1, 1]   -0.00349     0.0363 torch.float32\n",
      "    7                    model.2.cv1.bn.weight     False           96                 [96]       1.59      0.818 torch.float32\n",
      "    8                      model.2.cv1.bn.bias     False           96                 [96]      0.439      0.999 torch.float32\n",
      "    9                  model.2.cv2.conv.weight     False        18432      [96, 192, 1, 1]   -0.00226     0.0289 torch.float32\n",
      "   10                    model.2.cv2.bn.weight     False           96                 [96]      0.983      0.302 torch.float32\n",
      "   11                      model.2.cv2.bn.bias     False           96                 [96]     -0.263      0.675 torch.float32\n",
      "   12              model.2.m.0.cv1.conv.weight     False        20736       [48, 48, 3, 3]   -0.00069     0.0229 torch.float32\n",
      "   13                model.2.m.0.cv1.bn.weight     False           48                 [48]       1.48      0.467 torch.float32\n",
      "   14                  model.2.m.0.cv1.bn.bias     False           48                 [48]      0.558      0.902 torch.float32\n",
      "   15              model.2.m.0.cv2.conv.weight     False        20736       [48, 48, 3, 3]   -0.00105     0.0208 torch.float32\n",
      "   16                model.2.m.0.cv2.bn.weight     False           48                 [48]       1.19      0.319 torch.float32\n",
      "   17                  model.2.m.0.cv2.bn.bias     False           48                 [48]      0.386        1.1 torch.float32\n",
      "   18              model.2.m.1.cv1.conv.weight     False        20736       [48, 48, 3, 3]  -0.000838     0.0192 torch.float32\n",
      "   19                model.2.m.1.cv1.bn.weight     False           48                 [48]       1.11      0.239 torch.float32\n",
      "   20                  model.2.m.1.cv1.bn.bias     False           48                 [48]    -0.0649      0.852 torch.float32\n",
      "   21              model.2.m.1.cv2.conv.weight     False        20736       [48, 48, 3, 3]   -0.00124     0.0198 torch.float32\n",
      "   22                model.2.m.1.cv2.bn.weight     False           48                 [48]       1.91      0.405 torch.float32\n",
      "   23                  model.2.m.1.cv2.bn.bias     False           48                 [48]      0.432       1.01 torch.float32\n",
      "   24                      model.3.conv.weight     False       165888      [192, 96, 3, 3]  -0.000559     0.0123 torch.float32\n",
      "   25                        model.3.bn.weight     False          192                [192]       0.71      0.176 torch.float32\n",
      "   26                          model.3.bn.bias     False          192                [192]     -0.401      0.716 torch.float32\n",
      "   27                  model.4.cv1.conv.weight     False        36864     [192, 192, 1, 1]  -0.000846     0.0208 torch.float32\n",
      "   28                    model.4.cv1.bn.weight     False          192                [192]      0.923      0.467 torch.float32\n",
      "   29                      model.4.cv1.bn.bias     False          192                [192]      0.165      0.609 torch.float32\n",
      "   30                  model.4.cv2.conv.weight     False       110592     [192, 576, 1, 1]  -0.000797     0.0142 torch.float32\n",
      "   31                    model.4.cv2.bn.weight     False          192                [192]      0.918      0.209 torch.float32\n",
      "   32                      model.4.cv2.bn.bias     False          192                [192]     -0.642      0.657 torch.float32\n",
      "   33              model.4.m.0.cv1.conv.weight     False        82944       [96, 96, 3, 3]  -0.000771      0.011 torch.float32\n",
      "   34                model.4.m.0.cv1.bn.weight     False           96                 [96]      0.893       0.15 torch.float32\n",
      "   35                  model.4.m.0.cv1.bn.bias     False           96                 [96]     -0.839      0.521 torch.float32\n",
      "   36              model.4.m.0.cv2.conv.weight     False        82944       [96, 96, 3, 3]  -0.000474      0.011 torch.float32\n",
      "   37                model.4.m.0.cv2.bn.weight     False           96                 [96]      0.616      0.171 torch.float32\n",
      "   38                  model.4.m.0.cv2.bn.bias     False           96                 [96]     -0.172      0.545 torch.float32\n",
      "   39              model.4.m.1.cv1.conv.weight     False        82944       [96, 96, 3, 3]  -0.000849     0.0111 torch.float32\n",
      "   40                model.4.m.1.cv1.bn.weight     False           96                 [96]      0.865      0.138 torch.float32\n",
      "   41                  model.4.m.1.cv1.bn.bias     False           96                 [96]      -1.17      0.519 torch.float32\n",
      "   42              model.4.m.1.cv2.conv.weight     False        82944       [96, 96, 3, 3]  -0.000588     0.0104 torch.float32\n",
      "   43                model.4.m.1.cv2.bn.weight     False           96                 [96]      0.703      0.199 torch.float32\n",
      "   44                  model.4.m.1.cv2.bn.bias     False           96                 [96]     -0.237      0.429 torch.float32\n",
      "   45              model.4.m.2.cv1.conv.weight     False        82944       [96, 96, 3, 3]  -0.000769     0.0111 torch.float32\n",
      "   46                model.4.m.2.cv1.bn.weight     False           96                 [96]      0.767     0.0957 torch.float32\n",
      "   47                  model.4.m.2.cv1.bn.bias     False           96                 [96]      -1.36      0.455 torch.float32\n",
      "   48              model.4.m.2.cv2.conv.weight     False        82944       [96, 96, 3, 3]  -0.000461     0.0102 torch.float32\n",
      "   49                model.4.m.2.cv2.bn.weight     False           96                 [96]      0.868      0.166 torch.float32\n",
      "   50                  model.4.m.2.cv2.bn.bias     False           96                 [96]     -0.183       0.45 torch.float32\n",
      "   51              model.4.m.3.cv1.conv.weight     False        82944       [96, 96, 3, 3]  -0.000706     0.0108 torch.float32\n",
      "   52                model.4.m.3.cv1.bn.weight     False           96                 [96]       0.75      0.109 torch.float32\n",
      "   53                  model.4.m.3.cv1.bn.bias     False           96                 [96]      -1.37      0.402 torch.float32\n",
      "   54              model.4.m.3.cv2.conv.weight     False        82944       [96, 96, 3, 3]  -0.000467    0.00984 torch.float32\n",
      "   55                model.4.m.3.cv2.bn.weight     False           96                 [96]        1.4      0.245 torch.float32\n",
      "   56                  model.4.m.3.cv2.bn.bias     False           96                 [96]       0.11      0.438 torch.float32\n",
      "   57                      model.5.conv.weight     False       663552     [384, 192, 3, 3]   -6.2e-05    0.00703 torch.float32\n",
      "   58                        model.5.bn.weight     False          384                [384]      0.911      0.142 torch.float32\n",
      "   59                          model.5.bn.bias     False          384                [384]      -0.55       0.44 torch.float32\n",
      "   60                  model.6.cv1.conv.weight     False       147456     [384, 384, 1, 1]    -0.0009     0.0124 torch.float32\n",
      "   61                    model.6.cv1.bn.weight     False          384                [384]       1.12      0.478 torch.float32\n",
      "   62                      model.6.cv1.bn.bias     False          384                [384]     -0.263      0.477 torch.float32\n",
      "   63                  model.6.cv2.conv.weight     False       442368    [384, 1152, 1, 1]  -0.000493    0.00855 torch.float32\n",
      "   64                    model.6.cv2.bn.weight     False          384                [384]       1.05      0.141 torch.float32\n",
      "   65                      model.6.cv2.bn.bias     False          384                [384]      -1.02      0.483 torch.float32\n",
      "   66              model.6.m.0.cv1.conv.weight     False       331776     [192, 192, 3, 3]  -0.000487    0.00633 torch.float32\n",
      "   67                model.6.m.0.cv1.bn.weight     False          192                [192]       1.04      0.123 torch.float32\n",
      "   68                  model.6.m.0.cv1.bn.bias     False          192                [192]      -1.01      0.288 torch.float32\n",
      "   69              model.6.m.0.cv2.conv.weight     False       331776     [192, 192, 3, 3]  -0.000378    0.00649 torch.float32\n",
      "   70                model.6.m.0.cv2.bn.weight     False          192                [192]      0.746      0.153 torch.float32\n",
      "   71                  model.6.m.0.cv2.bn.bias     False          192                [192]     -0.494      0.351 torch.float32\n",
      "   72              model.6.m.1.cv1.conv.weight     False       331776     [192, 192, 3, 3]  -0.000471    0.00653 torch.float32\n",
      "   73                model.6.m.1.cv1.bn.weight     False          192                [192]      0.968     0.0956 torch.float32\n",
      "   74                  model.6.m.1.cv1.bn.bias     False          192                [192]      -1.21      0.288 torch.float32\n",
      "   75              model.6.m.1.cv2.conv.weight     False       331776     [192, 192, 3, 3]  -0.000268    0.00631 torch.float32\n",
      "   76                model.6.m.1.cv2.bn.weight     False          192                [192]      0.841      0.134 torch.float32\n",
      "   77                  model.6.m.1.cv2.bn.bias     False          192                [192]     -0.597      0.302 torch.float32\n",
      "   78              model.6.m.2.cv1.conv.weight     False       331776     [192, 192, 3, 3]  -0.000465    0.00667 torch.float32\n",
      "   79                model.6.m.2.cv1.bn.weight     False          192                [192]      0.939     0.0835 torch.float32\n",
      "   80                  model.6.m.2.cv1.bn.bias     False          192                [192]      -1.35      0.294 torch.float32\n",
      "   81              model.6.m.2.cv2.conv.weight     False       331776     [192, 192, 3, 3]   -0.00029     0.0063 torch.float32\n",
      "   82                model.6.m.2.cv2.bn.weight     False          192                [192]          1      0.138 torch.float32\n",
      "   83                  model.6.m.2.cv2.bn.bias     False          192                [192]      -0.53      0.266 torch.float32\n",
      "   84              model.6.m.3.cv1.conv.weight     False       331776     [192, 192, 3, 3]  -0.000501    0.00666 torch.float32\n",
      "   85                model.6.m.3.cv1.bn.weight     False          192                [192]      0.924     0.0729 torch.float32\n",
      "   86                  model.6.m.3.cv1.bn.bias     False          192                [192]      -1.44      0.269 torch.float32\n",
      "   87              model.6.m.3.cv2.conv.weight     False       331776     [192, 192, 3, 3]   -0.00029    0.00608 torch.float32\n",
      "   88                model.6.m.3.cv2.bn.weight     False          192                [192]        1.5      0.109 torch.float32\n",
      "   89                  model.6.m.3.cv2.bn.bias     False          192                [192]     -0.296      0.224 torch.float32\n",
      "   90                      model.7.conv.weight     False  1.99066e+06     [576, 384, 3, 3]   -0.00021    0.00416 torch.float32\n",
      "   91                        model.7.bn.weight     False          576                [576]       1.08      0.107 torch.float32\n",
      "   92                          model.7.bn.bias     False          576                [576]     -0.762      0.182 torch.float32\n",
      "   93                  model.8.cv1.conv.weight     False       331776     [576, 576, 1, 1]  -0.000919    0.00784 torch.float32\n",
      "   94                    model.8.cv1.bn.weight     False          576                [576]       1.11       0.18 torch.float32\n",
      "   95                      model.8.cv1.bn.bias     False          576                [576]     -0.611      0.527 torch.float32\n",
      "   96                  model.8.cv2.conv.weight     False       663552    [576, 1152, 1, 1]  -0.000542    0.00573 torch.float32\n",
      "   97                    model.8.cv2.bn.weight     False          576                [576]        1.2      0.126 torch.float32\n",
      "   98                      model.8.cv2.bn.bias     False          576                [576]     -0.433      0.195 torch.float32\n",
      "   99              model.8.m.0.cv1.conv.weight     False       746496     [288, 288, 3, 3]  -0.000324    0.00455 torch.float32\n",
      "  100                model.8.m.0.cv1.bn.weight     False          288                [288]       1.23       0.12 torch.float32\n",
      "  101                  model.8.m.0.cv1.bn.bias     False          288                [288]      -0.71      0.311 torch.float32\n",
      "  102              model.8.m.0.cv2.conv.weight     False       746496     [288, 288, 3, 3]  -0.000386     0.0044 torch.float32\n",
      "  103                model.8.m.0.cv2.bn.weight     False          288                [288]       1.06      0.162 torch.float32\n",
      "  104                  model.8.m.0.cv2.bn.bias     False          288                [288]     -0.658      0.261 torch.float32\n",
      "  105              model.8.m.1.cv1.conv.weight     False       746496     [288, 288, 3, 3]   -0.00029    0.00417 torch.float32\n",
      "  106                model.8.m.1.cv1.bn.weight     False          288                [288]        1.2      0.121 torch.float32\n",
      "  107                  model.8.m.1.cv1.bn.bias     False          288                [288]     -0.756      0.234 torch.float32\n",
      "  108              model.8.m.1.cv2.conv.weight     False       746496     [288, 288, 3, 3]   -0.00029    0.00396 torch.float32\n",
      "  109                model.8.m.1.cv2.bn.weight     False          288                [288]       1.43      0.186 torch.float32\n",
      "  110                  model.8.m.1.cv2.bn.bias     False          288                [288]     -0.247       0.15 torch.float32\n",
      "  111                  model.9.cv1.conv.weight     False       165888     [288, 576, 1, 1]   -0.00164    0.00963 torch.float32\n",
      "  112                    model.9.cv1.bn.weight     False          288                [288]      0.926      0.164 torch.float32\n",
      "  113                      model.9.cv1.bn.bias     False          288                [288]      0.436      0.376 torch.float32\n",
      "  114                  model.9.cv2.conv.weight     False       663552    [576, 1152, 1, 1]  -3.86e-05    0.00649 torch.float32\n",
      "  115                    model.9.cv2.bn.weight     False          576                [576]      0.935      0.142 torch.float32\n",
      "  116                      model.9.cv2.bn.bias     False          576                [576]      -1.09      0.342 torch.float32\n",
      "  117                 model.12.cv1.conv.weight     False       368640     [384, 960, 1, 1]  -0.000869     0.0104 torch.float32\n",
      "  118                   model.12.cv1.bn.weight     False          384                [384]       1.05      0.176 torch.float32\n",
      "  119                     model.12.cv1.bn.bias     False          384                [384]      -0.86      0.601 torch.float32\n",
      "  120                 model.12.cv2.conv.weight     False       294912     [384, 768, 1, 1]     -0.001    0.00986 torch.float32\n",
      "  121                   model.12.cv2.bn.weight     False          384                [384]      0.863      0.147 torch.float32\n",
      "  122                     model.12.cv2.bn.bias     False          384                [384]      -0.73      0.408 torch.float32\n",
      "  123             model.12.m.0.cv1.conv.weight     False       331776     [192, 192, 3, 3]  -0.000616    0.00753 torch.float32\n",
      "  124               model.12.m.0.cv1.bn.weight     False          192                [192]       1.11      0.122 torch.float32\n",
      "  125                 model.12.m.0.cv1.bn.bias     False          192                [192]     -0.856      0.438 torch.float32\n",
      "  126             model.12.m.0.cv2.conv.weight     False       331776     [192, 192, 3, 3]  -0.000589    0.00724 torch.float32\n",
      "  127               model.12.m.0.cv2.bn.weight     False          192                [192]       0.95      0.119 torch.float32\n",
      "  128                 model.12.m.0.cv2.bn.bias     False          192                [192]     -0.852       0.45 torch.float32\n",
      "  129             model.12.m.1.cv1.conv.weight     False       331776     [192, 192, 3, 3]  -0.000662    0.00616 torch.float32\n",
      "  130               model.12.m.1.cv1.bn.weight     False          192                [192]       1.07      0.137 torch.float32\n",
      "  131                 model.12.m.1.cv1.bn.bias     False          192                [192]     -0.834      0.303 torch.float32\n",
      "  132             model.12.m.1.cv2.conv.weight     False       331776     [192, 192, 3, 3]  -0.000423    0.00586 torch.float32\n",
      "  133               model.12.m.1.cv2.bn.weight     False          192                [192]      0.961      0.115 torch.float32\n",
      "  134                 model.12.m.1.cv2.bn.bias     False          192                [192]     -0.611      0.275 torch.float32\n",
      "  135                 model.15.cv1.conv.weight     False       110592     [192, 576, 1, 1]  -0.000687     0.0133 torch.float32\n",
      "  136                   model.15.cv1.bn.weight     False          192                [192]      0.664      0.189 torch.float32\n",
      "  137                     model.15.cv1.bn.bias     False          192                [192]     -0.244      0.715 torch.float32\n",
      "  138                 model.15.cv2.conv.weight     False        73728     [192, 384, 1, 1]  -0.000833     0.0124 torch.float32\n",
      "  139                   model.15.cv2.bn.weight     False          192                [192]      0.588      0.252 torch.float32\n",
      "  140                     model.15.cv2.bn.bias     False          192                [192]     -0.546       0.72 torch.float32\n",
      "  141             model.15.m.0.cv1.conv.weight     False        82944       [96, 96, 3, 3]  -0.000699     0.0124 torch.float32\n",
      "  142               model.15.m.0.cv1.bn.weight     False           96                 [96]      0.824      0.114 torch.float32\n",
      "  143                 model.15.m.0.cv1.bn.bias     False           96                 [96]     -0.702      0.505 torch.float32\n",
      "  144             model.15.m.0.cv2.conv.weight     False        82944       [96, 96, 3, 3]  -0.000911     0.0115 torch.float32\n",
      "  145               model.15.m.0.cv2.bn.weight     False           96                 [96]      0.837      0.127 torch.float32\n",
      "  146                 model.15.m.0.cv2.bn.bias     False           96                 [96]     -0.616      0.487 torch.float32\n",
      "  147             model.15.m.1.cv1.conv.weight     False        82944       [96, 96, 3, 3]   -0.00106     0.0101 torch.float32\n",
      "  148               model.15.m.1.cv1.bn.weight     False           96                 [96]      0.811      0.154 torch.float32\n",
      "  149                 model.15.m.1.cv1.bn.bias     False           96                 [96]     -0.803      0.489 torch.float32\n",
      "  150             model.15.m.1.cv2.conv.weight     False        82944       [96, 96, 3, 3]    -0.0006    0.00934 torch.float32\n",
      "  151               model.15.m.1.cv2.bn.weight     False           96                 [96]      0.965      0.256 torch.float32\n",
      "  152                 model.15.m.1.cv2.bn.bias     False           96                 [96]     -0.251      0.475 torch.float32\n",
      "  153                     model.16.conv.weight     False       331776     [192, 192, 3, 3]  -0.000196    0.00479 torch.float32\n",
      "  154                       model.16.bn.weight     False          192                [192]      0.864      0.159 torch.float32\n",
      "  155                         model.16.bn.bias     False          192                [192]     -0.469      0.264 torch.float32\n",
      "  156                 model.18.cv1.conv.weight     False       221184     [384, 576, 1, 1]  -0.000555    0.00781 torch.float32\n",
      "  157                   model.18.cv1.bn.weight     False          384                [384]      0.992      0.127 torch.float32\n",
      "  158                     model.18.cv1.bn.bias     False          384                [384]     -0.495      0.322 torch.float32\n",
      "  159                 model.18.cv2.conv.weight     False       294912     [384, 768, 1, 1]  -0.000438    0.00617 torch.float32\n",
      "  160                   model.18.cv2.bn.weight     False          384                [384]      0.934      0.278 torch.float32\n",
      "  161                     model.18.cv2.bn.bias     False          384                [384]     -0.658      0.391 torch.float32\n",
      "  162             model.18.m.0.cv1.conv.weight     False       331776     [192, 192, 3, 3]  -0.000426    0.00582 torch.float32\n",
      "  163               model.18.m.0.cv1.bn.weight     False          192                [192]      0.988       0.16 torch.float32\n",
      "  164                 model.18.m.0.cv1.bn.bias     False          192                [192]     -0.758      0.374 torch.float32\n",
      "  165             model.18.m.0.cv2.conv.weight     False       331776     [192, 192, 3, 3]  -0.000366    0.00542 torch.float32\n",
      "  166               model.18.m.0.cv2.bn.weight     False          192                [192]       1.02      0.123 torch.float32\n",
      "  167                 model.18.m.0.cv2.bn.bias     False          192                [192]      -0.69      0.384 torch.float32\n",
      "  168             model.18.m.1.cv1.conv.weight     False       331776     [192, 192, 3, 3]  -0.000461    0.00478 torch.float32\n",
      "  169               model.18.m.1.cv1.bn.weight     False          192                [192]      0.976      0.155 torch.float32\n",
      "  170                 model.18.m.1.cv1.bn.bias     False          192                [192]     -0.778      0.274 torch.float32\n",
      "  171             model.18.m.1.cv2.conv.weight     False       331776     [192, 192, 3, 3]  -0.000266    0.00461 torch.float32\n",
      "  172               model.18.m.1.cv2.bn.weight     False          192                [192]       1.28       0.17 torch.float32\n",
      "  173                 model.18.m.1.cv2.bn.bias     False          192                [192]      -0.41      0.313 torch.float32\n",
      "  174                     model.19.conv.weight     False   1.3271e+06     [384, 384, 3, 3]  -0.000108    0.00222 torch.float32\n",
      "  175                       model.19.bn.weight     False          384                [384]      0.913      0.104 torch.float32\n",
      "  176                         model.19.bn.bias     False          384                [384]     -0.325      0.112 torch.float32\n",
      "  177                 model.21.cv1.conv.weight     False       552960     [576, 960, 1, 1]  -0.000287    0.00413 torch.float32\n",
      "  178                   model.21.cv1.bn.weight     False          576                [576]       1.03      0.115 torch.float32\n",
      "  179                     model.21.cv1.bn.bias     False          576                [576]     -0.322      0.195 torch.float32\n",
      "  180                 model.21.cv2.conv.weight     False       663552    [576, 1152, 1, 1]  -0.000236    0.00331 torch.float32\n",
      "  181                   model.21.cv2.bn.weight     False          576                [576]        1.1      0.192 torch.float32\n",
      "  182                     model.21.cv2.bn.bias     False          576                [576]     -0.333      0.167 torch.float32\n",
      "  183             model.21.m.0.cv1.conv.weight     False       746496     [288, 288, 3, 3]  -0.000195    0.00297 torch.float32\n",
      "  184               model.21.m.0.cv1.bn.weight     False          288                [288]       1.11      0.119 torch.float32\n",
      "  185                 model.21.m.0.cv1.bn.bias     False          288                [288]     -0.402      0.215 torch.float32\n",
      "  186             model.21.m.0.cv2.conv.weight     False       746496     [288, 288, 3, 3]   -0.00023    0.00289 torch.float32\n",
      "  187               model.21.m.0.cv2.bn.weight     False          288                [288]       1.05      0.117 torch.float32\n",
      "  188                 model.21.m.0.cv2.bn.bias     False          288                [288]     -0.505      0.234 torch.float32\n",
      "  189             model.21.m.1.cv1.conv.weight     False       746496     [288, 288, 3, 3]  -0.000217    0.00259 torch.float32\n",
      "  190               model.21.m.1.cv1.bn.weight     False          288                [288]       1.09      0.119 torch.float32\n",
      "  191                 model.21.m.1.cv1.bn.bias     False          288                [288]     -0.455      0.161 torch.float32\n",
      "  192             model.21.m.1.cv2.conv.weight     False       746496     [288, 288, 3, 3]  -0.000136    0.00246 torch.float32\n",
      "  193               model.21.m.1.cv2.bn.weight     False          288                [288]       1.26       0.12 torch.float32\n",
      "  194                 model.21.m.1.cv2.bn.bias     False          288                [288]     -0.253      0.133 torch.float32\n",
      "  195             model.22.cv2.0.0.conv.weight     False       110592      [64, 192, 3, 3]  -0.000249    0.00689 torch.float32\n",
      "  196               model.22.cv2.0.0.bn.weight     False           64                 [64]       1.05      0.468 torch.float32\n",
      "  197                 model.22.cv2.0.0.bn.bias     False           64                 [64]    -0.0182      0.857 torch.float32\n",
      "  198             model.22.cv2.0.1.conv.weight     False        36864       [64, 64, 3, 3]  -0.000132     0.0102 torch.float32\n",
      "  199               model.22.cv2.0.1.bn.weight     False           64                 [64]       2.21      0.923 torch.float32\n",
      "  200                 model.22.cv2.0.1.bn.bias     False           64                 [64]      0.953      0.544 torch.float32\n",
      "  201                  model.22.cv2.0.2.weight     False         4096       [64, 64, 1, 1]  -8.72e-07     0.0443 torch.float32\n",
      "  202                    model.22.cv2.0.2.bias     False           64                 [64]      0.999        1.2 torch.float32\n",
      "  203             model.22.cv2.1.0.conv.weight     False       221184      [64, 384, 3, 3]  -0.000153    0.00453 torch.float32\n",
      "  204               model.22.cv2.1.0.bn.weight     False           64                 [64]       1.18      0.457 torch.float32\n",
      "  205                 model.22.cv2.1.0.bn.bias     False           64                 [64]     0.0164       0.68 torch.float32\n",
      "  206             model.22.cv2.1.1.conv.weight     False        36864       [64, 64, 3, 3]   7.15e-05    0.00938 torch.float32\n",
      "  207               model.22.cv2.1.1.bn.weight     False           64                 [64]       2.49       0.67 torch.float32\n",
      "  208                 model.22.cv2.1.1.bn.bias     False           64                 [64]      0.923      0.467 torch.float32\n",
      "  209                  model.22.cv2.1.2.weight     False         4096       [64, 64, 1, 1]    8.1e-07     0.0479 torch.float32\n",
      "  210                    model.22.cv2.1.2.bias     False           64                 [64]      0.999      0.965 torch.float32\n",
      "  211             model.22.cv2.2.0.conv.weight     False       331776      [64, 576, 3, 3]  -0.000122    0.00304 torch.float32\n",
      "  212               model.22.cv2.2.0.bn.weight     False           64                 [64]       1.32      0.282 torch.float32\n",
      "  213                 model.22.cv2.2.0.bn.bias     False           64                 [64]    -0.0885       0.52 torch.float32\n",
      "  214             model.22.cv2.2.1.conv.weight     False        36864       [64, 64, 3, 3]   6.21e-05    0.00742 torch.float32\n",
      "  215               model.22.cv2.2.1.bn.weight     False           64                 [64]       3.11      0.505 torch.float32\n",
      "  216                 model.22.cv2.2.1.bn.bias     False           64                 [64]      0.885      0.494 torch.float32\n",
      "  217                  model.22.cv2.2.2.weight     False         4096       [64, 64, 1, 1]   8.67e-07     0.0446 torch.float32\n",
      "  218                    model.22.cv2.2.2.bias     False           64                 [64]          1      0.836 torch.float32\n",
      "  219             model.22.cv3.0.0.conv.weight     False       331776     [192, 192, 3, 3]  -0.000257    0.00452 torch.float32\n",
      "  220               model.22.cv3.0.0.bn.weight     False          192                [192]       0.88       0.29 torch.float32\n",
      "  221                 model.22.cv3.0.0.bn.bias     False          192                [192]     -0.326      0.509 torch.float32\n",
      "  222             model.22.cv3.0.1.conv.weight     False       331776     [192, 192, 3, 3]  -0.000342    0.00412 torch.float32\n",
      "  223               model.22.cv3.0.1.bn.weight     False          192                [192]       1.97      0.634 torch.float32\n",
      "  224                 model.22.cv3.0.1.bn.bias     False          192                [192]      0.828       1.03 torch.float32\n",
      "  225                  model.22.cv3.0.2.weight     False        15360      [80, 192, 1, 1]   -0.00607       0.03 torch.float32\n",
      "  226                    model.22.cv3.0.2.bias     False           80                 [80]      -11.5      0.969 torch.float32\n",
      "  227             model.22.cv3.1.0.conv.weight     False       663552     [192, 384, 3, 3]  -0.000134    0.00296 torch.float32\n",
      "  228               model.22.cv3.1.0.bn.weight     False          192                [192]       1.05      0.292 torch.float32\n",
      "  229                 model.22.cv3.1.0.bn.bias     False          192                [192]     -0.199      0.506 torch.float32\n",
      "  230             model.22.cv3.1.1.conv.weight     False       331776     [192, 192, 3, 3]  -0.000359    0.00344 torch.float32\n",
      "  231               model.22.cv3.1.1.bn.weight     False          192                [192]       2.08      0.705 torch.float32\n",
      "  232                 model.22.cv3.1.1.bn.bias     False          192                [192]      0.759      0.911 torch.float32\n",
      "  233                  model.22.cv3.1.2.weight     False        15360      [80, 192, 1, 1]    -0.0057     0.0279 torch.float32\n",
      "  234                    model.22.cv3.1.2.bias     False           80                 [80]      -10.6      0.777 torch.float32\n",
      "  235             model.22.cv3.2.0.conv.weight     False       995328     [192, 576, 3, 3]  -7.69e-05      0.002 torch.float32\n",
      "  236               model.22.cv3.2.0.bn.weight     False          192                [192]        1.1      0.229 torch.float32\n",
      "  237                 model.22.cv3.2.0.bn.bias     False          192                [192]     -0.238      0.321 torch.float32\n",
      "  238             model.22.cv3.2.1.conv.weight     False       331776     [192, 192, 3, 3]  -0.000331    0.00272 torch.float32\n",
      "  239               model.22.cv3.2.1.bn.weight     False          192                [192]        2.1      0.469 torch.float32\n",
      "  240                 model.22.cv3.2.1.bn.bias     False          192                [192]        0.8      0.904 torch.float32\n",
      "  241                  model.22.cv3.2.2.weight     False        15360      [80, 192, 1, 1]   -0.00546     0.0246 torch.float32\n",
      "  242                    model.22.cv3.2.2.bias     False           80                 [80]      -9.75      0.666 torch.float32\n",
      "  243                 model.22.dfl.conv.weight     False           16        [1, 16, 1, 1]        7.5       4.76 torch.float32\n",
      "YOLOv8m summary: 295 layers, 25902640 parameters, 0 gradients, 79.3 GFLOPs\n",
      "(295, 25902640, 0, 79.3204224)\n"
     ]
    }
   ],
   "source": [
    "print(model.info(detailed=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO(\"yolov8s.yaml\")  # build a new model from YAML\n",
    "model = YOLO(r\"D:\\PC\\cyvision\\soybean_phenomic\\yolo_soybean\\ckpts\\yolov8s.pt\")  # load a pretrained model (recommended for training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer                                     name  gradient   parameters                shape         mu      sigma\n",
      "    0                      model.0.conv.weight     False          864        [32, 3, 3, 3]   -0.00203       0.13 torch.float32\n",
      "    1                        model.0.bn.weight     False           32                 [32]        3.5          1 torch.float32\n",
      "    2                          model.0.bn.bias     False           32                 [32]     -0.613       2.97 torch.float32\n",
      "    3                      model.1.conv.weight     False        18432       [64, 32, 3, 3]  -0.000742     0.0358 torch.float32\n",
      "    4                        model.1.bn.weight     False           64                 [64]       3.37      0.704 torch.float32\n",
      "    5                          model.1.bn.bias     False           64                 [64]      0.439       1.18 torch.float32\n",
      "    6                  model.2.cv1.conv.weight     False         4096       [64, 64, 1, 1]   -0.00687     0.0533 torch.float32\n",
      "    7                    model.2.cv1.bn.weight     False           64                 [64]        1.8       0.95 torch.float32\n",
      "    8                      model.2.cv1.bn.bias     False           64                 [64]      0.392       1.37 torch.float32\n",
      "    9                  model.2.cv2.conv.weight     False         6144       [64, 96, 1, 1]   -0.00341     0.0475 torch.float32\n",
      "   10                    model.2.cv2.bn.weight     False           64                 [64]       1.21       0.35 torch.float32\n",
      "   11                      model.2.cv2.bn.bias     False           64                 [64]   -0.00756      0.724 torch.float32\n",
      "   12              model.2.m.0.cv1.conv.weight     False         9216       [32, 32, 3, 3]   -0.00135     0.0348 torch.float32\n",
      "   13                model.2.m.0.cv1.bn.weight     False           32                 [32]        2.2       0.57 torch.float32\n",
      "   14                  model.2.m.0.cv1.bn.bias     False           32                 [32]       0.42       1.44 torch.float32\n",
      "   15              model.2.m.0.cv2.conv.weight     False         9216       [32, 32, 3, 3]   -0.00147     0.0318 torch.float32\n",
      "   16                model.2.m.0.cv2.bn.weight     False           32                 [32]       1.77      0.542 torch.float32\n",
      "   17                  model.2.m.0.cv2.bn.bias     False           32                 [32]      0.829       1.43 torch.float32\n",
      "   18                      model.3.conv.weight     False        73728      [128, 64, 3, 3]     -0.001     0.0189 torch.float32\n",
      "   19                        model.3.bn.weight     False          128                [128]      0.829      0.203 torch.float32\n",
      "   20                          model.3.bn.bias     False          128                [128]     -0.269      0.722 torch.float32\n",
      "   21                  model.4.cv1.conv.weight     False        16384     [128, 128, 1, 1]   -0.00212      0.032 torch.float32\n",
      "   22                    model.4.cv1.bn.weight     False          128                [128]      0.821      0.372 torch.float32\n",
      "   23                      model.4.cv1.bn.bias     False          128                [128]      0.025      0.669 torch.float32\n",
      "   24                  model.4.cv2.conv.weight     False        32768     [128, 256, 1, 1]   -0.00172     0.0265 torch.float32\n",
      "   25                    model.4.cv2.bn.weight     False          128                [128]      0.911      0.219 torch.float32\n",
      "   26                      model.4.cv2.bn.bias     False          128                [128]     -0.463      0.702 torch.float32\n",
      "   27              model.4.m.0.cv1.conv.weight     False        36864       [64, 64, 3, 3]   -0.00104     0.0201 torch.float32\n",
      "   28                model.4.m.0.cv1.bn.weight     False           64                 [64]      0.889      0.183 torch.float32\n",
      "   29                  model.4.m.0.cv1.bn.bias     False           64                 [64]      -0.69      0.676 torch.float32\n",
      "   30              model.4.m.0.cv2.conv.weight     False        36864       [64, 64, 3, 3]   -0.00102     0.0185 torch.float32\n",
      "   31                model.4.m.0.cv2.bn.weight     False           64                 [64]      0.775      0.208 torch.float32\n",
      "   32                  model.4.m.0.cv2.bn.bias     False           64                 [64]     -0.117      0.606 torch.float32\n",
      "   33              model.4.m.1.cv1.conv.weight     False        36864       [64, 64, 3, 3]   -0.00141     0.0184 torch.float32\n",
      "   34                model.4.m.1.cv1.bn.weight     False           64                 [64]      0.771      0.104 torch.float32\n",
      "   35                  model.4.m.1.cv1.bn.bias     False           64                 [64]      -1.04      0.563 torch.float32\n",
      "   36              model.4.m.1.cv2.conv.weight     False        36864       [64, 64, 3, 3]  -0.000975     0.0175 torch.float32\n",
      "   37                model.4.m.1.cv2.bn.weight     False           64                 [64]       1.08      0.266 torch.float32\n",
      "   38                  model.4.m.1.cv2.bn.bias     False           64                 [64]      0.226      0.684 torch.float32\n",
      "   39                      model.5.conv.weight     False       294912     [256, 128, 3, 3]  -0.000185     0.0112 torch.float32\n",
      "   40                        model.5.bn.weight     False          256                [256]      0.891      0.185 torch.float32\n",
      "   41                          model.5.bn.bias     False          256                [256]      -0.55      0.556 torch.float32\n",
      "   42                  model.6.cv1.conv.weight     False        65536     [256, 256, 1, 1]   -0.00173     0.0197 torch.float32\n",
      "   43                    model.6.cv1.bn.weight     False          256                [256]      0.998      0.367 torch.float32\n",
      "   44                      model.6.cv1.bn.bias     False          256                [256]     -0.296      0.579 torch.float32\n",
      "   45                  model.6.cv2.conv.weight     False       131072     [256, 512, 1, 1]   -0.00112     0.0165 torch.float32\n",
      "   46                    model.6.cv2.bn.weight     False          256                [256]      0.936      0.183 torch.float32\n",
      "   47                      model.6.cv2.bn.bias     False          256                [256]     -0.885      0.624 torch.float32\n",
      "   48              model.6.m.0.cv1.conv.weight     False       147456     [128, 128, 3, 3]  -0.000907     0.0117 torch.float32\n",
      "   49                model.6.m.0.cv1.bn.weight     False          128                [128]       1.07      0.145 torch.float32\n",
      "   50                  model.6.m.0.cv1.bn.bias     False          128                [128]      -1.11      0.461 torch.float32\n",
      "   51              model.6.m.0.cv2.conv.weight     False       147456     [128, 128, 3, 3]  -0.000819     0.0114 torch.float32\n",
      "   52                model.6.m.0.cv2.bn.weight     False          128                [128]      0.916      0.203 torch.float32\n",
      "   53                  model.6.m.0.cv2.bn.bias     False          128                [128]     -0.376      0.483 torch.float32\n",
      "   54              model.6.m.1.cv1.conv.weight     False       147456     [128, 128, 3, 3]  -0.000845     0.0118 torch.float32\n",
      "   55                model.6.m.1.cv1.bn.weight     False          128                [128]      0.965      0.127 torch.float32\n",
      "   56                  model.6.m.1.cv1.bn.bias     False          128                [128]      -1.26      0.558 torch.float32\n",
      "   57              model.6.m.1.cv2.conv.weight     False       147456     [128, 128, 3, 3]  -0.000596     0.0111 torch.float32\n",
      "   58                model.6.m.1.cv2.bn.weight     False          128                [128]        1.4      0.221 torch.float32\n",
      "   59                  model.6.m.1.cv2.bn.bias     False          128                [128]     -0.157      0.505 torch.float32\n",
      "   60                      model.7.conv.weight     False  1.17965e+06     [512, 256, 3, 3]  -0.000377    0.00686 torch.float32\n",
      "   61                        model.7.bn.weight     False          512                [512]        1.1       0.13 torch.float32\n",
      "   62                          model.7.bn.bias     False          512                [512]     -0.844      0.247 torch.float32\n",
      "   63                  model.8.cv1.conv.weight     False       262144     [512, 512, 1, 1]   -0.00155     0.0123 torch.float32\n",
      "   64                    model.8.cv1.bn.weight     False          512                [512]       1.11      0.199 torch.float32\n",
      "   65                      model.8.cv1.bn.bias     False          512                [512]     -0.838      0.513 torch.float32\n",
      "   66                  model.8.cv2.conv.weight     False       393216     [512, 768, 1, 1]     -0.001     0.0104 torch.float32\n",
      "   67                    model.8.cv2.bn.weight     False          512                [512]       1.24      0.163 torch.float32\n",
      "   68                      model.8.cv2.bn.bias     False          512                [512]     -0.726      0.279 torch.float32\n",
      "   69              model.8.m.0.cv1.conv.weight     False       589824     [256, 256, 3, 3]  -0.000453    0.00786 torch.float32\n",
      "   70                model.8.m.0.cv1.bn.weight     False          256                [256]       1.23      0.146 torch.float32\n",
      "   71                  model.8.m.0.cv1.bn.bias     False          256                [256]      -1.01      0.484 torch.float32\n",
      "   72              model.8.m.0.cv2.conv.weight     False       589824     [256, 256, 3, 3]  -0.000633    0.00759 torch.float32\n",
      "   73                model.8.m.0.cv2.bn.weight     False          256                [256]       1.62      0.245 torch.float32\n",
      "   74                  model.8.m.0.cv2.bn.bias     False          256                [256]     -0.572      0.319 torch.float32\n",
      "   75                  model.9.cv1.conv.weight     False       131072     [256, 512, 1, 1]   -0.00229     0.0148 torch.float32\n",
      "   76                    model.9.cv1.bn.weight     False          256                [256]      0.944      0.196 torch.float32\n",
      "   77                      model.9.cv1.bn.bias     False          256                [256]      0.786      0.438 torch.float32\n",
      "   78                  model.9.cv2.conv.weight     False       524288    [512, 1024, 1, 1]  -1.53e-05    0.00963 torch.float32\n",
      "   79                    model.9.cv2.bn.weight     False          512                [512]      0.982      0.174 torch.float32\n",
      "   80                      model.9.cv2.bn.bias     False          512                [512]      -1.31      0.509 torch.float32\n",
      "   81                 model.12.cv1.conv.weight     False       196608     [256, 768, 1, 1]   -0.00129     0.0153 torch.float32\n",
      "   82                   model.12.cv1.bn.weight     False          256                [256]          1      0.212 torch.float32\n",
      "   83                     model.12.cv1.bn.bias     False          256                [256]     -0.747      0.686 torch.float32\n",
      "   84                 model.12.cv2.conv.weight     False        98304     [256, 384, 1, 1]   -0.00224     0.0165 torch.float32\n",
      "   85                   model.12.cv2.bn.weight     False          256                [256]       0.89      0.201 torch.float32\n",
      "   86                     model.12.cv2.bn.bias     False          256                [256]     -0.598      0.554 torch.float32\n",
      "   87             model.12.m.0.cv1.conv.weight     False       147456     [128, 128, 3, 3]   -0.00102     0.0122 torch.float32\n",
      "   88               model.12.m.0.cv1.bn.weight     False          128                [128]      0.949      0.138 torch.float32\n",
      "   89                 model.12.m.0.cv1.bn.bias     False          128                [128]     -0.997       0.52 torch.float32\n",
      "   90             model.12.m.0.cv2.conv.weight     False       147456     [128, 128, 3, 3]  -0.000695     0.0112 torch.float32\n",
      "   91               model.12.m.0.cv2.bn.weight     False          128                [128]      0.956      0.135 torch.float32\n",
      "   92                 model.12.m.0.cv2.bn.bias     False          128                [128]     -0.455      0.485 torch.float32\n",
      "   93                 model.15.cv1.conv.weight     False        49152     [128, 384, 1, 1]   -0.00122     0.0194 torch.float32\n",
      "   94                   model.15.cv1.bn.weight     False          128                [128]      0.612      0.214 torch.float32\n",
      "   95                     model.15.cv1.bn.bias     False          128                [128]     -0.276      0.804 torch.float32\n",
      "   96                 model.15.cv2.conv.weight     False        24576     [128, 192, 1, 1]   -0.00125     0.0214 torch.float32\n",
      "   97                   model.15.cv2.bn.weight     False          128                [128]      0.609       0.26 torch.float32\n",
      "   98                     model.15.cv2.bn.bias     False          128                [128]     -0.377      0.751 torch.float32\n",
      "   99             model.15.m.0.cv1.conv.weight     False        36864       [64, 64, 3, 3]   -0.00126     0.0178 torch.float32\n",
      "  100               model.15.m.0.cv1.bn.weight     False           64                 [64]      0.775      0.123 torch.float32\n",
      "  101                 model.15.m.0.cv1.bn.bias     False           64                 [64]     -0.726      0.592 torch.float32\n",
      "  102             model.15.m.0.cv2.conv.weight     False        36864       [64, 64, 3, 3]   -0.00112     0.0167 torch.float32\n",
      "  103               model.15.m.0.cv2.bn.weight     False           64                 [64]      0.856      0.187 torch.float32\n",
      "  104                 model.15.m.0.cv2.bn.bias     False           64                 [64]     -0.247       0.61 torch.float32\n",
      "  105                     model.16.conv.weight     False       147456     [128, 128, 3, 3]  -0.000348    0.00818 torch.float32\n",
      "  106                       model.16.bn.weight     False          128                [128]       0.97      0.194 torch.float32\n",
      "  107                         model.16.bn.bias     False          128                [128]     -0.493      0.392 torch.float32\n",
      "  108                 model.18.cv1.conv.weight     False        98304     [256, 384, 1, 1]  -0.000932     0.0126 torch.float32\n",
      "  109                   model.18.cv1.bn.weight     False          256                [256]      0.938       0.16 torch.float32\n",
      "  110                     model.18.cv1.bn.bias     False          256                [256]     -0.487      0.451 torch.float32\n",
      "  111                 model.18.cv2.conv.weight     False        98304     [256, 384, 1, 1]   -0.00102     0.0117 torch.float32\n",
      "  112                   model.18.cv2.bn.weight     False          256                [256]      0.882      0.299 torch.float32\n",
      "  113                     model.18.cv2.bn.bias     False          256                [256]     -0.727      0.527 torch.float32\n",
      "  114             model.18.m.0.cv1.conv.weight     False       147456     [128, 128, 3, 3]  -0.000797    0.00972 torch.float32\n",
      "  115               model.18.m.0.cv1.bn.weight     False          128                [128]      0.841      0.163 torch.float32\n",
      "  116                 model.18.m.0.cv1.bn.bias     False          128                [128]      -0.98      0.525 torch.float32\n",
      "  117             model.18.m.0.cv2.conv.weight     False       147456     [128, 128, 3, 3]  -0.000474    0.00897 torch.float32\n",
      "  118               model.18.m.0.cv2.bn.weight     False          128                [128]        1.3      0.232 torch.float32\n",
      "  119                 model.18.m.0.cv2.bn.bias     False          128                [128]     -0.405      0.492 torch.float32\n",
      "  120                     model.19.conv.weight     False       589824     [256, 256, 3, 3]  -0.000215    0.00424 torch.float32\n",
      "  121                       model.19.bn.weight     False          256                [256]      0.897      0.161 torch.float32\n",
      "  122                         model.19.bn.bias     False          256                [256]     -0.533      0.201 torch.float32\n",
      "  123                 model.21.cv1.conv.weight     False       393216     [512, 768, 1, 1]  -0.000583    0.00717 torch.float32\n",
      "  124                   model.21.cv1.bn.weight     False          512                [512]       1.02      0.169 torch.float32\n",
      "  125                     model.21.cv1.bn.bias     False          512                [512]      -0.61      0.349 torch.float32\n",
      "  126                 model.21.cv2.conv.weight     False       393216     [512, 768, 1, 1]  -0.000541    0.00586 torch.float32\n",
      "  127                   model.21.cv2.bn.weight     False          512                [512]       1.12       0.24 torch.float32\n",
      "  128                     model.21.cv2.bn.bias     False          512                [512]     -0.669      0.276 torch.float32\n",
      "  129             model.21.m.0.cv1.conv.weight     False       589824     [256, 256, 3, 3]  -0.000351    0.00483 torch.float32\n",
      "  130               model.21.m.0.cv1.bn.weight     False          256                [256]       1.04      0.169 torch.float32\n",
      "  131                 model.21.m.0.cv1.bn.bias     False          256                [256]     -0.869      0.358 torch.float32\n",
      "  132             model.21.m.0.cv2.conv.weight     False       589824     [256, 256, 3, 3]   -0.00025    0.00449 torch.float32\n",
      "  133               model.21.m.0.cv2.bn.weight     False          256                [256]       1.33      0.188 torch.float32\n",
      "  134                 model.21.m.0.cv2.bn.bias     False          256                [256]     -0.583      0.302 torch.float32\n",
      "  135             model.22.cv2.0.0.conv.weight     False        73728      [64, 128, 3, 3]  -0.000563    0.00969 torch.float32\n",
      "  136               model.22.cv2.0.0.bn.weight     False           64                 [64]       1.01      0.361 torch.float32\n",
      "  137                 model.22.cv2.0.0.bn.bias     False           64                 [64]     -0.214      0.717 torch.float32\n",
      "  138             model.22.cv2.0.1.conv.weight     False        36864       [64, 64, 3, 3]  -0.000354     0.0114 torch.float32\n",
      "  139               model.22.cv2.0.1.bn.weight     False           64                 [64]       2.34       1.03 torch.float32\n",
      "  140                 model.22.cv2.0.1.bn.bias     False           64                 [64]       1.01      0.623 torch.float32\n",
      "  141                  model.22.cv2.0.2.weight     False         4096       [64, 64, 1, 1]   2.39e-06     0.0462 torch.float32\n",
      "  142                    model.22.cv2.0.2.bias     False           64                 [64]          1       1.39 torch.float32\n",
      "  143             model.22.cv2.1.0.conv.weight     False       147456      [64, 256, 3, 3]  -0.000253    0.00663 torch.float32\n",
      "  144               model.22.cv2.1.0.bn.weight     False           64                 [64]       1.17      0.409 torch.float32\n",
      "  145                 model.22.cv2.1.0.bn.bias     False           64                 [64]     -0.108      0.676 torch.float32\n",
      "  146             model.22.cv2.1.1.conv.weight     False        36864       [64, 64, 3, 3]  -0.000268      0.011 torch.float32\n",
      "  147               model.22.cv2.1.1.bn.weight     False           64                 [64]       2.47      0.871 torch.float32\n",
      "  148                 model.22.cv2.1.1.bn.bias     False           64                 [64]      0.817      0.535 torch.float32\n",
      "  149                  model.22.cv2.1.2.weight     False         4096       [64, 64, 1, 1]  -2.78e-07     0.0523 torch.float32\n",
      "  150                    model.22.cv2.1.2.bias     False           64                 [64]          1       1.35 torch.float32\n",
      "  151             model.22.cv2.2.0.conv.weight     False       294912      [64, 512, 3, 3]  -0.000161    0.00459 torch.float32\n",
      "  152               model.22.cv2.2.0.bn.weight     False           64                 [64]       1.45      0.336 torch.float32\n",
      "  153                 model.22.cv2.2.0.bn.bias     False           64                 [64]     -0.268      0.598 torch.float32\n",
      "  154             model.22.cv2.2.1.conv.weight     False        36864       [64, 64, 3, 3]    -0.0003    0.00989 torch.float32\n",
      "  155               model.22.cv2.2.1.bn.weight     False           64                 [64]       2.96      0.747 torch.float32\n",
      "  156                 model.22.cv2.2.1.bn.bias     False           64                 [64]      0.853      0.566 torch.float32\n",
      "  157                  model.22.cv2.2.2.weight     False         4096       [64, 64, 1, 1]   3.86e-06     0.0557 torch.float32\n",
      "  158                    model.22.cv2.2.2.bias     False           64                 [64]          1       1.26 torch.float32\n",
      "  159             model.22.cv3.0.0.conv.weight     False       147456     [128, 128, 3, 3]  -0.000545     0.0069 torch.float32\n",
      "  160               model.22.cv3.0.0.bn.weight     False          128                [128]      0.825      0.282 torch.float32\n",
      "  161                 model.22.cv3.0.0.bn.bias     False          128                [128]     -0.442      0.622 torch.float32\n",
      "  162             model.22.cv3.0.1.conv.weight     False       147456     [128, 128, 3, 3]   -0.00063    0.00624 torch.float32\n",
      "  163               model.22.cv3.0.1.bn.weight     False          128                [128]       2.31      0.624 torch.float32\n",
      "  164                 model.22.cv3.0.1.bn.bias     False          128                [128]       1.17       1.32 torch.float32\n",
      "  165                  model.22.cv3.0.2.weight     False        10240      [80, 128, 1, 1]   -0.00936     0.0382 torch.float32\n",
      "  166                    model.22.cv3.0.2.bias     False           80                 [80]      -11.4       1.07 torch.float32\n",
      "  167             model.22.cv3.1.0.conv.weight     False       294912     [128, 256, 3, 3]  -0.000266    0.00505 torch.float32\n",
      "  168               model.22.cv3.1.0.bn.weight     False          128                [128]       1.02      0.302 torch.float32\n",
      "  169                 model.22.cv3.1.0.bn.bias     False          128                [128]     -0.306      0.741 torch.float32\n",
      "  170             model.22.cv3.1.1.conv.weight     False       147456     [128, 128, 3, 3]  -0.000671    0.00575 torch.float32\n",
      "  171               model.22.cv3.1.1.bn.weight     False          128                [128]       2.41      0.989 torch.float32\n",
      "  172                 model.22.cv3.1.1.bn.bias     False          128                [128]       1.05       1.12 torch.float32\n",
      "  173                  model.22.cv3.1.2.weight     False        10240      [80, 128, 1, 1]   -0.00853     0.0381 torch.float32\n",
      "  174                    model.22.cv3.1.2.bias     False           80                 [80]      -10.5      0.859 torch.float32\n",
      "  175             model.22.cv3.2.0.conv.weight     False       589824     [128, 512, 3, 3]  -0.000144    0.00348 torch.float32\n",
      "  176               model.22.cv3.2.0.bn.weight     False          128                [128]       1.17      0.273 torch.float32\n",
      "  177                 model.22.cv3.2.0.bn.bias     False          128                [128]     -0.402      0.653 torch.float32\n",
      "  178             model.22.cv3.2.1.conv.weight     False       147456     [128, 128, 3, 3]  -0.000624    0.00504 torch.float32\n",
      "  179               model.22.cv3.2.1.bn.weight     False          128                [128]       2.64      0.963 torch.float32\n",
      "  180                 model.22.cv3.2.1.bn.bias     False          128                [128]      0.946       1.14 torch.float32\n",
      "  181                  model.22.cv3.2.2.weight     False        10240      [80, 128, 1, 1]   -0.00716     0.0364 torch.float32\n",
      "  182                    model.22.cv3.2.2.bias     False           80                 [80]      -9.63      0.843 torch.float32\n",
      "  183                 model.22.dfl.conv.weight     False           16        [1, 16, 1, 1]        7.5       4.76 torch.float32\n",
      "YOLOv8s summary: 225 layers, 11166560 parameters, 0 gradients, 28.8 GFLOPs\n",
      "(225, 11166560, 0, 28.816844800000002)\n"
     ]
    }
   ],
   "source": [
    "print(model.info(detailed=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
